{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPCrqHbXeJ06+qZncq6ag1h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/toni-ramchandani/AIMasterClassTTT/blob/main/Section1_8_Introduction_to_AI_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HcSJjb8kgcaj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Natural Language Processing (NLP) Overview**\n",
        "\n",
        "NLP is a field of artificial intelligence that enables computers to understand, interpret, and generate human language. Its applications range from simple tasks, like text summarization and sentiment analysis, to advanced functions, like machine translation, chatbots, and virtual assistants. NLP bridges computer science and linguistics by processing language data, using both rule-based and machine learning approaches.\n",
        "\n",
        "### **Core Concepts and Techniques in NLP**\n",
        "\n",
        "1. **Tokenization**: Splits text into smaller units like words or sentences, enabling easier analysis. Word and sentence tokenization are common methods.\n",
        "\n",
        "2. **Stemming and Lemmatization**: Both reduce words to their root forms. **Stemming** trims suffixes, while **lemmatization** uses vocabulary and grammar to find the root form.\n",
        "\n",
        "3. **Part-of-Speech (POS) Tagging**: Identifies grammatical roles (e.g., noun, verb) of words in a sentence, assisting in understanding sentence structure and meaning.\n",
        "\n",
        "4. **Named Entity Recognition (NER)**: Identifies entities (e.g., names, locations, organizations) within text, useful for extracting structured data from unstructured text.\n",
        "\n",
        "5. **Bag of Words (BoW) and TF-IDF**: These are feature extraction techniques. **BoW** represents text based on word frequency, while **TF-IDF** (Term Frequency-Inverse Document Frequency) weighs words according to importance in documents.\n",
        "\n",
        "6. **Word Embeddings**: Word embeddings, like Word2Vec and GloVe, map words to vectors in continuous space, preserving semantic relationships. Advanced embeddings, such as BERT and GPT, capture context-sensitive meanings.\n",
        "\n",
        "7. **Sequence Models**: Models like **Recurrent Neural Networks (RNNs)** and **Long Short-Term Memory (LSTM)** networks are commonly used for tasks involving sequential data, like text generation and machine translation.\n",
        "\n",
        "8. **Transformer Models**: Transformers (like BERT and GPT) have revolutionized NLP, enabling high-performance in tasks like translation and question-answering. They use self-attention mechanisms to capture word relationships across entire texts.\n",
        "\n",
        "### **Example Applications of NLP**\n",
        "\n",
        "1. **Sentiment Analysis**: Detects the sentiment of text, useful in social media monitoring and customer feedback.\n",
        "2. **Machine Translation**: Translates text from one language to another (e.g., Google Translate).\n",
        "3. **Chatbots and Virtual Assistants**: NLP powers conversation systems like Siri, Alexa, and customer service bots.\n",
        "4. **Speech Recognition**: Converts spoken language into text, as used in virtual assistants.\n",
        "5. **Document Summarization**: Creates concise summaries of long documents, valuable for news and legal industries.\n"
      ],
      "metadata": {
        "id": "O9ek89a6gdq2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **Example Code Snippet for Sentiment Analysis with NLTK**\n",
        "\n",
        "```python\n",
        "import nltk\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "# Initialize Sentiment Intensity Analyzer\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Analyze sentiment of a sentence\n",
        "text = \"I love NLP! It's so interesting and powerful.\"\n",
        "score = sia.polarity_scores(text)\n",
        "print(\"Sentiment Score:\", score)\n",
        "```\n",
        "\n",
        "### **Example Code for Text Classification with SpaCy**\n",
        "\n",
        "```python\n",
        "import spacy\n",
        "from spacy.lang.en import English\n",
        "\n",
        "# Load SpaCy model\n",
        "nlp = English()\n",
        "\n",
        "# Example text\n",
        "text = \"Apple is looking at buying a UK-based startup for $1 billion.\"\n",
        "\n",
        "# Process text and print named entities\n",
        "doc = nlp(text)\n",
        "for ent in doc.ents:\n",
        "    print(ent.text, ent.label_)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "Y9Xu5zOcgjOs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('vader_lexicon')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1iiQ2XDMgohJ",
        "outputId": "c4dba9b7-22b1-4264-bfb8-1d8a61ea9172"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "# Initialize Sentiment Intensity Analyzer\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Analyze sentiment of a sentence\n",
        "text = \"I love NLP! It's so interesting and powerful.\"\n",
        "score = sia.polarity_scores(text)\n",
        "print(\"Sentiment Score:\", score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KG74CEZbhHsV",
        "outputId": "46ac74ae-bd8d-4367-de89-18053689e040"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment Score: {'neg': 0.0, 'neu': 0.266, 'pos': 0.734, 'compound': 0.9011}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example Code for Text Classification with SpaCy"
      ],
      "metadata": {
        "id": "rtFDsEqQhJc1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "# Load the spaCy model with NER\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Example text\n",
        "text = \"Apple is looking at buying a UK-based startup for $1 billion.\"\n",
        "\n",
        "# Process text and print named entities\n",
        "doc = nlp(text)\n",
        "for ent in doc.ents:\n",
        "    print(ent.text, ent.label_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-SmvE3x0gxaU",
        "outputId": "93e4567f-dc5f-4014-d47a-de4ecfc6f53b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apple ORG\n",
            "UK GPE\n",
            "$1 billion MONEY\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code provides a foundation for implementing NLP tasks like sentiment analysis, entity recognition, and tokenization. NLP techniques continue to evolve, offering increasingly sophisticated ways to process and understand human language."
      ],
      "metadata": {
        "id": "x78YflYrglUu"
      }
    }
  ]
}