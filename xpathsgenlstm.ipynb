{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO5NCOoluNXGDii0OQFYNPM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/gist/toniramchandani1/c513e5c870e465a38964a90dd57dd83f/xpathsgenlstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import Libraries**\n",
        "The first section of the code imports necessary libraries for the task. numpy is used for numerical operations, tensorflow and specifically its keras API for building the neural network model, and train_test_split from sklearn to split the dataset into training and testing sets."
      ],
      "metadata": {
        "id": "LyejxcStVPjx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Embedding, TimeDistributed\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "5kOAmlA6VK5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define Dataset**\n",
        "Here, a sample dataset of HTML elements and their corresponding XPaths is defined. Each element is a dictionary with two keys: 'element' for the HTML snippet and 'xpath' for its XPath."
      ],
      "metadata": {
        "id": "AQ30nMIXVYKQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = [\n",
        "    {'element': '<html><head></head></html>', 'xpath': '/html/head'},\n",
        "    {'element': '<div class=\"container\"></div>', 'xpath': '//div[@class=\"container\"]'},\n",
        "    {'element': '<ul><li>Item 1</li><li>Item 2</li></ul>', 'xpath': '//ul/li'},\n",
        "    {'element': '<div><span class=\"text\">Example</span></div>', 'xpath': '//div/span[@class=\"text\"]'},\n",
        "    {'element': '<a href=\"https://example.com\">Link</a>', 'xpath': '//a[@href=\"https://example.com\"]'},\n",
        "    {'element': '<input type=\"text\" name=\"firstname\">', 'xpath': '//input[@type=\"text\"]'},\n",
        "    {'element': '<button id=\"submit\">Submit</button>', 'xpath': '//button[@id=\"submit\"]'},\n",
        "    {'element': '<section><header>Header</header></section>', 'xpath': '/section/header'},\n",
        "    {'element': '<footer><p>Copyright 2021</p></footer>', 'xpath': '//footer/p'},\n",
        "    {'element': '<nav><ul><li><a href=\"#home\">Home</a></li></ul></nav>', 'xpath': '//nav//a[@href=\"#home\"]'},\n",
        "    {'element': '<article><h2>Title</h2><p>Paragraph</p></article>', 'xpath': '//article//p'},\n",
        "    {'element': '<form><label for=\"email\">Email:</label><input type=\"email\" id=\"email\"></form>', 'xpath': '//form//input[@type=\"email\"]'},\n",
        "    {'element': '<table><tr><td>Cell 1</td><td>Cell 2</td></tr></table>', 'xpath': '//table/tr/td'},\n",
        "    {'element': '<img src=\"image.jpg\" alt=\"Image\">', 'xpath': '//img[@alt=\"Image\"]'},\n",
        "    {'element': '<aside><h3>Related</h3><p>Content</p></aside>', 'xpath': '//aside/p'},\n",
        "    {'element': '<section id=\"main-content\"><div class=\"highlight\">Featured</div></section>', 'xpath': '//section[@id=\"main-content\"]/div[@class=\"highlight\"]'},\n",
        "    {'element': '<ol><li class=\"item\">First item</li><li class=\"item\">Second item</li></ol>', 'xpath': '//ol/li[@class=\"item\"]'},\n",
        "    {'element': '<header><h1>Welcome</h1><nav><ul><li>About</li><li>Contact</li></ul></nav></header>', 'xpath': '//header/nav/ul/li'},\n",
        "    {'element': '<div class=\"login\"><form><input type=\"password\" name=\"password\"></form></div>', 'xpath': '//div[@class=\"login\"]//input[@type=\"password\"]'},\n",
        "    {'element': '<article><section><p>Some text here</p></section></article>', 'xpath': '//article//section/p'},\n",
        "    {'element': '<iframe src=\"video.html\"></iframe>', 'xpath': '//iframe[@src=\"video.html\"]'},\n",
        "    {'element': '<main><section><h2>Introduction</h2><p>Welcome to our site.</p></section></main>', 'xpath': '//main//section/p'},\n",
        "    {'element': '<ul class=\"menu\"><li><a href=\"#home\">Home</a></li><li><a href=\"#about\">About</a></li></ul>', 'xpath': '//ul[@class=\"menu\"]/li/a'},\n",
        "    {'element': '<div class=\"header\"><span class=\"date\">Jan 1, 2024</span><h1>New Year</h1></div>', 'xpath': '//div[@class=\"header\"]/span[@class=\"date\"]'},\n",
        "    {'element': '<blockquote cite=\"http://example.com/facts\">Interesting Fact</blockquote>', 'xpath': '//blockquote[@cite]'},\n",
        "    {'element': '<label for=\"search\">Search:</label><input id=\"search\" type=\"search\">', 'xpath': '//input[@id=\"search\"]'},\n",
        "    {'element': '<details><summary>More Info</summary><p>Detailed Information</p></details>', 'xpath': '//details/summary'},\n",
        "    {'element': '<figure><img src=\"photo.png\" alt=\"Photo\"><figcaption>Photo Caption</figcaption></figure>', 'xpath': '//figure/figcaption'},\n",
        "    {'element': '<datalist id=\"browsers\"><option value=\"Chrome\"></option><option value=\"Firefox\"></option></datalist>', 'xpath': '//datalist[@id=\"browsers\"]/option'},\n",
        "    {'element': '<div class=\"comments\"><comment>Great article!</comment><comment>Thanks for sharing.</comment></div>', 'xpath': '//div[@class=\"comments\"]/comment'},\n",
        "    {'element': '<bdi dir=\"rtl\">This text will be reversed</bdi>', 'xpath': '//bdi[@dir=\"rtl\"]'},\n",
        "    {'element': '<mark>This is highlighted text</mark>', 'xpath': '//mark'},\n",
        "    {'element': '<time datetime=\"2024-01-01\">January 1st, 2024</time>', 'xpath': '//time[@datetime=\"2024-01-01\"]'}\n",
        "\n",
        "    # Add more samples as needed...\n",
        "]"
      ],
      "metadata": {
        "id": "r3MI3UwjVXn9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocess Dataset**\n",
        "This section calculates the maximum length among all HTML elements and XPaths to standardize input size, separates elements and XPaths into lists, and creates a vocabulary from all unique characters in the dataset. It then encodes HTML elements and XPaths into numerical sequences based on this vocabulary."
      ],
      "metadata": {
        "id": "fpgG7gVfVhwt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = max(max(len(sample['element']), len(sample['xpath'])) for sample in dataset)\n",
        "elements = [sample['element'] for sample in dataset]\n",
        "xpaths = [sample['xpath'] for sample in dataset]\n",
        "\n",
        "all_chars = ''.join(set(''.join(elements) + ''.join(xpaths)))\n",
        "vocabulary = sorted(set(all_chars))\n",
        "char_to_index = {char: index + 1 for index, char in enumerate(vocabulary)}\n",
        "x_encoded = [[char_to_index[char] for char in element] for element in elements]\n",
        "y_encoded = [[char_to_index[char] for char in xpath] for xpath in xpaths]"
      ],
      "metadata": {
        "id": "EfGvileeVd0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pad Sequences**\n",
        "To ensure all input sequences have the same length, this part pads shorter sequences with zeros at the end (post padding)."
      ],
      "metadata": {
        "id": "aqiK6p0wVoA7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_padded = pad_sequences(x_encoded, maxlen=max_length, padding='post', value=0)\n",
        "y_padded = pad_sequences(y_encoded, maxlen=max_length, padding='post', value=0)"
      ],
      "metadata": {
        "id": "LmvHlDOUVs92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Split Dataset**\n",
        "Splits the padded sequences into training and testing sets using a standard 80/20 split."
      ],
      "metadata": {
        "id": "LBnWS93mVv3U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x_padded, y_padded, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "h1Q7j7pXVzZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define Model Architecture**\n",
        "Defines a Sequential model with an Embedding layer to learn dense representations of characters, an LSTM layer to capture sequences, and a TimeDistributed Dense layer to make predictions at each sequence step."
      ],
      "metadata": {
        "id": "vDTVfFXOV7Yv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(vocabulary) + 1  # Vocabulary size\n",
        "embedding_dim = 64\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_length),\n",
        "    LSTM(128, return_sequences=True),\n",
        "    TimeDistributed(Dense(vocab_size, activation='softmax'))\n",
        "])"
      ],
      "metadata": {
        "id": "LobZRDpRV08d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Compile and Train Model**\n",
        "Compiles the model with sparse_categorical_crossentropy as the loss function (suitable for multi-class classification tasks) and trains it using the training data. y_train and y_test are reshaped to fit the expected input shape for the loss function."
      ],
      "metadata": {
        "id": "SD26mKiNV__O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "y_train_reshaped = np.expand_dims(y_train, -1)\n",
        "y_test_reshaped = np.expand_dims(y_test, -1)\n",
        "\n",
        "model.fit(x_train, y_train_reshaped, epochs=10, batch_size=32, validation_data=(x_test, y_test_reshaped))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOSs6PEsV2sU",
        "outputId": "ea44a246-65ca-482e-8f69-6aeb3f03d659"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1/1 [==============================] - 4s 4s/step - loss: 3.1822 - accuracy: 0.0000e+00 - val_loss: 3.1758 - val_accuracy: 0.1724\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 3.1606 - accuracy: 0.5517 - val_loss: 3.1731 - val_accuracy: 0.1379\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 3.1391 - accuracy: 0.6552 - val_loss: 3.1702 - val_accuracy: 0.1379\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 3.1161 - accuracy: 0.6552 - val_loss: 3.1668 - val_accuracy: 0.1379\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 3.0894 - accuracy: 0.6552 - val_loss: 3.1627 - val_accuracy: 0.1379\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 3.0564 - accuracy: 0.6552 - val_loss: 3.1573 - val_accuracy: 0.1379\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 3.0137 - accuracy: 0.6552 - val_loss: 3.1500 - val_accuracy: 0.1379\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 2.9561 - accuracy: 0.6552 - val_loss: 3.1397 - val_accuracy: 0.1379\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 2.8754 - accuracy: 0.6552 - val_loss: 3.1239 - val_accuracy: 0.1379\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 2.7577 - accuracy: 0.6552 - val_loss: 3.0987 - val_accuracy: 0.1379\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x78169f14f4f0>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Generate XPath Predictions**\n",
        "Encodes a new HTML element using the vocabulary, pads the sequence, predicts the corresponding XPath using the trained model, and decodes the prediction back into characters."
      ],
      "metadata": {
        "id": "ACEjWgMsWEbU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_element = '<div class=\"example\"></div>'\n",
        "sample_encoded = [char_to_index[char] for char in sample_element if char in char_to_index]\n",
        "sample_padded = pad_sequences([sample_encoded], maxlen=max_length, padding='post', value=0)\n",
        "prediction = model.predict(sample_padded)\n",
        "predicted_xpath_encoded = np.argmax(prediction, axis=-1)[0]\n",
        "predicted_xpath = ''.join([vocabulary[index - 1] for index in predicted_xpath_encoded if index > 0])\n",
        "\n",
        "print(\"Predicted XPath:\", predicted_xpath)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsbcAKuiV4fU",
        "outputId": "951c2f77-f7c9-4e49-facf-8dcaf4479beb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 608ms/step\n",
            "Predicted XPath: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code demonstrates how to preprocess data, build a simple sequence-to-sequence model with TensorFlow's Keras API, train the model, and use it to predict the XPath of a given HTML element. Adjustments may be needed for more complex HTML/XPath pairs or larger datasets."
      ],
      "metadata": {
        "id": "I4Z4MXfcWKo9"
      }
    }
  ]
}